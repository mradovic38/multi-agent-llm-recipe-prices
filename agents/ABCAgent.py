import json

class ABCAgent:
    def __init__(self, model, prompt_path:str = None, params_path:str = None):
        """
        Initializes the ABCAgent with a model and optional paths to a prompt file and parameters file.

        Args:
            model: The model object used for generating responses.
            prompt_path (str, optional): Path to a file containing the prompt template. Defaults to None.
            params_path (str, optional): Path to a JSON file containing model parameters. Defaults to None.
        """
        
        self.model = model
        
        if prompt_path:
            with open(prompt_path, 'r') as file:
                self.prompt_text = file.read()
        
        if params_path:
            with open(params_path, 'r') as f:
                self.params = json.load(f)
                
        
    def _query_llm(self, **kwargs) -> str:
        """
        Queries the LLM by building the query, generating a response using the model, and cleaning up the output.

        Args:
            **kwargs: Additional keyword arguments to pass to the query builder.

        Returns:
            str: The cleaned-up response generated by the model.
        """

        query = self._build_query(**kwargs)

        generated_text =  self.model.prompt(query, self.params)

        return self._cleanup_response(generated_text)
    
    
    def _build_query(self, **kwargs) -> str:
        """
        Builds the query to be sent to the model. This method should be overridden in subclasses to customize
        how the query is constructed.

        Args:
            **kwargs: Keyword arguments for customizing the prompt.

        Returns:
            str: The formatted query to be passed to the model
        """
        pass

    def _cleanup_response(self, generated_text) -> str:
        """
        Cleans up the raw response generated by the model. This method should be overridden in subclasses to
        customize how the response is processed before being returned to the user.

        Args:
            generated_text (str): The raw text generated by the model.

        Returns:
            str: The cleaned-up response text, or raw response if not overridden.
        """
        return generated_text